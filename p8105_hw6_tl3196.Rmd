---
title: "p8106_hw5_tl3196"
author: "Tianshu Liu"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	message = FALSE, 
  dpi = 300,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
# download data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

...

## Problem 2

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, ", ", state), 
    resolved = as.numeric(disposition == "Closed by arrest"),
    ) %>% 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black")
  ) %>% 
  mutate(
    victim_age = as.numeric(victim_age),
    victim_race = fct(victim_race)
  )
  
homicide_df
```

Fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors for the city of Baltimore, MD

```{r}
# fit logistic regression for Baltimore
balt_logi_reg = 
  homicide_df %>% filter(city_state == "Baltimore, MD") %>% 
  glm(
  formula = resolved ~ victim_age + victim_sex + victim_race, 
  data = .,
  family = binomial()
) 

summary(balt_logi_reg)

balt_logi_reg %>% broom::tidy()
```

Obtain the estimate and CI of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed. 

```{r}
# estimate and CI of the adjusted OR for sex = male in solving homicides 
balt_logi_reg %>% 
  broom::tidy() %>% 
  filter(str_detect(term,"Male")) %>% 
  mutate(
    log_or = estimate,
    adj_or = exp(estimate),
    adj_or_ci_low = exp(estimate - 1.96 * std.error),
    adj_or_ci_high = exp(estimate + 1.96 * std.error)
    ) %>% 
  select(log_or, adj_or, adj_or_ci_low, adj_or_ci_high)
```

Iterate each cities in the data set.

```{r}
homicide_or = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    logi_reg = map(.x = data, ~glm(formula = resolved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    logi_results = map(logi_reg, broom::tidy)
  ) %>% 
  select(-data, -logi_reg) %>% 
  unnest(logi_results) %>% 
  filter(str_detect(term,"Male")) %>% 
  mutate(
    log_or = estimate,
    adj_or = exp(estimate),
    adj_or_ci_low = exp(estimate - 1.96 * std.error),
    adj_or_ci_high = exp(estimate + 1.96 * std.error)
    ) %>% 
  select(city_state, log_or, adj_or, adj_or_ci_low, adj_or_ci_high)

homicide_or
```

Create a plot that shows the estimated ORs and CIs for each city. 

```{r}
homicide_or %>% 
  mutate(
    city_state = fct_reorder(city_state, adj_or)
  ) %>% 
  ggplot(aes(x = city_state, y = adj_or, color = city_state)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = adj_or_ci_low, ymax = adj_or_ci_high)) + 
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(size=6, angle=45, hjust = 1)) + 
  labs(
    x = "City & State",
    y = "Adjusted Odd Ratio",
    title = "Estimated ORs and CIs Comparing Male to Female Victims"
  )
```

## Problem 3

```{r}
# import data from csv file
birthweight_df = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  )

# check missing data 
skimr::skim(birthweight_df)

birthweight_df
```

```{r}
# histogram plot for baby weight
birthweight_df %>% 
  ggplot(aes(x = bwt)) + 
  geom_histogram() + 
  labs(
    x = "Birthweight",
    y = "Count",
    title = "Histogram for Birthweight"
  )
```

```{r}
# boxplot for baby weight
birthweight_df %>% 
  ggplot(aes(y = bwt)) + 
  geom_boxplot() + 
  labs(
    y = "Birthweight",
    title = "Boxplot for Birthweight"
  )
```

From the plots, the distribution of `bwt` is almost symmetric and normal. 
Thus, no transformation is necessary before regression.

Use `LASSO` to select predictors in the hypothesized model.

```{r}
# LASSO
# define response variable & potential predictors 
response <- pull(birthweight_df, bwt)
predictors <- data.matrix(birthweight_df %>% select(-bwt))

library(glmnet)

# perform cross-validation to find optimal lambda value
cv_model <- cv.glmnet(predictors, response, alpha = 1)

# find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda

# produce plot of test MSE by lambda value
plot(cv_model) 

# find coefficients of best model
best_model <- glmnet(predictors, response, alpha = 1, lambda = best_lambda)
coef(best_model)
```

Remain the predictors in the hypothesized regression model whose coefficients is not zero in the table above.

```{r}
# hypothesized model
hypo_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + menarche + mheight + momage + mrace + parity + smoken + wtgain, data = birthweight_df)

# calculate rmse for hypothesized model
rmse(hypo_model, birthweight_df)

# make a plot of model residuals against fitted values
birthweight_df %>% 
  add_predictions(hypo_model) %>% 
  add_residuals(hypo_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .3) + 
  geom_hline(yintercept=0, linetype="dashed", color = "red") + 
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = "Residuals vs Fitted Values"
  )
```

Compare models using cross validation. 

 
 - One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
# split cross validation df
cv_df = crossv_mc(birthweight_df, 100)

# cross validation 
cv_df = 
  cv_df %>% 
  mutate(
    train = map(train, as.tibble),
    test = map(test, as.tibble)
  ) %>% 
  mutate(
    hypo_model = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + menarche + mheight + momage + mrace + parity + smoken + wtgain, data = .x)),
    main_model = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    interact_model = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + babysex * bhead + babysex * blength + bhead * blength + babysex * bhead * blength, data = .x))
  ) %>% 
  mutate(
    rmse_hypo = map2_dbl(.x = hypo_model, .y = test, ~rmse(.x, .y)),
    rmse_main = map2_dbl(.x = main_model, .y = test, ~rmse(.x, .y)),
    rmse_interact = map2_dbl(.x = interact_model, .y = test, ~rmse(.x, .y))
  )

cv_df 

# boxplot for 3 models
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot() + 
  labs(
    x = "Models",
    y = "RMSE",
    titles = "RMSE Boxplots for Models"
  )
```

According to the boxplot, the RMSEs are `hypo < interact < main`. Since lower RMSE indicates a better fit, the hypothesized model selecting predictors based on LASSO has the best fit among all models.
